程序利用mapreduce方式，计算某个hdfs目录下的所有文档的单词统计数量。

方法一：
1、首先设置HADOOP_CLASSPATH环境变量：

//把需要依赖的 jar 包临时写进 HADOOP_CLASSPATH 环境变量
export HADOOP_CLASSPATH="$HADOOP_CLASSPATH:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*":/etc/hadoop/conf;


2、执行任务

hadoop jar hdfsmrtesttbdsauthparra-1.0-SNAPSHOT.jar com.hadooptest.hdfsmrtesttbdsauthparra.WordCount /tmp/input /tmp/output/0002 wPl9zgEpT4pJlxKbv2mHrpJEPt9q3q56yFnp testuser LluWnYeM2qtaxqEwzGXwFftvCvNJ1g4F

五个参数：
参数1：/tmp/input 表示输入文件目录（这里是hdfs目录，不是linux文件系统的本地目录）
参数2：/tmp/output/0002 表示输出文件目录（这里是hdfs目录，不是linux文件系统的本地目录）
参数3：wPl9zgEpT4pJlxKbv2mHrpJEPt9q3q56yFnp 表示id
参数4：testuser 表示用户名
参数5：LluWnYeM2qtaxqEwzGXwFftvCvNJ1g4F 表示key


方法二：
java -Djava.library.path=/usr/hdp/2.2.0.0-2041/hadoop/lib/native/:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64/ -classpath ./hdfsmrtesttbdsauthparra-1.0-SNAPSHOT.jar:/usr/hdp/2.2.0.0-2041/hadoop/client/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/etc/hadoop/conf com.hadooptest.hdfsmrtesttbdsauthparra.WordCount /tmp/input /tmp/output/0005 wPl9zgEpT4pJlxKbv2mHrpJEPt9q3q56yFnp testuser LluWnYeM2qtaxqEwzGXwFftvCvNJ1g4F