1、设置环境hadoop认证的变量
方法一：通过在 /etc/profile文件设置hadoop认证的环境变量，将认证参数进行设置。详细方法，请参照
《TBDS4.0身份认证&权限管控使用手册》的2.1.2章节
方法二：直接在linux系统设置环境变量：
export hadoop_security_authentication_tbds_secureid=wPl9zgEpT4pJlxKbv2mHrpJEPt9q3q56yFnp
export hadoop_security_authentication_tbds_username=testuser
export hadoop_security_authentication_tbds_securekey=LluWnYeM2qtaxqEwzGXwFftvCvNJ1g4F


2、登录安装有hadoop client、spark client 和 yarn client的服务器，进入到/usr/hdp/2.2.0.0-2041/spark目录：

cd /usr/hdp/2.2.0.0-2041/spark

运行测试程序，有三种运行方式。具体执行以下命令：

（1） 提交到本地：
./bin/spark-submit --master local[*] --executor-memory 3g --driver-memory 2g --num-executors 3 --executor-cores 2 --class com.sparktest.sparkjavademo.WordCountJavaDemo /tmp/sparkdemo/sparkjavademo-1.0-SNAPSHOT.jar hdfs://hdfsCluster/tmp/input/


（2） 提交到yarn-client：
./bin/spark-submit --master yarn-client --executor-memory 3g --driver-memory 2g --num-executors 3 --executor-cores 2 --class com.sparktest.sparkjavademo.WordCountJavaDemo /tmp/sparkdemo/sparkjavademo-1.0-SNAPSHOT.jar hdfs://hdfsCluster/tmp/input/


（3） 提交到 yarn-cluster集群：
./bin/spark-submit --master yarn-cluster --executor-memory 3g --driver-memory 2g --num-executors 3 --executor-cores 2 --class com.sparktest.sparkjavademo.WordCountJavaDemo /tmp/sparkdemo/sparkjavademo-1.0-SNAPSHOT.jar hdfs://hdfsCluster/tmp/input/
或者：
./bin/spark-submit --master yarn --deploy-mode cluster --executor-memory 3g --driver-memory 2g --num-executors 3 --executor-cores 2 --class com.sparktest.sparkjavademo.WordCountJavaDemo /tmp/sparkdemo/sparkjavademo-1.0-SNAPSHOT.jar hdfs://hdfsCluster/tmp/input/

注意：以上几种任务执行提交方式，--executor-memory 3g --driver-memory 2g 都依赖于以下两个参数：
yarn.scheduler.maximum-allocation-mb 和 yarn.nodemanager.resource.memory-mb，必须不大于这两个对应的参数。